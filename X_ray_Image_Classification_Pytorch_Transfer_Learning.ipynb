{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Pneumonia** is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. We will test the ability of a **deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays**.\n",
        "\n",
        "By **fine-tuning a pre-trained convolutional neural network**, specifically the **ResNet-18 model**, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources."
      ],
      "metadata": {
        "id": "zMnnwRl9dKmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the chestxrays.zip file (code provided below), you will find your dataset inside the data/chestxrays folder divided into test and train folders.\n",
        "\n",
        "There are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a train_loader and a test_loader using the DataLoader class from the PyTorch library."
      ],
      "metadata": {
        "id": "hYVLRXBedL47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJDx-ENeibvi",
        "outputId": "04027a76-e8e7-41e4-f02e-4f7a187f778f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/chest-xray-pneumonia?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.29G/2.29G [00:17<00:00, 145MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/paultimothymooney/chest-xray-pneumonia/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHz3L7hzclV-"
      },
      "outputs": [],
      "source": [
        "# # Make sure to run this cell to use torchmetrics.\n",
        "!pip install torch torchvision torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "# -------------------------\n",
        "# Data loading\n",
        "import random\n",
        "import numpy as np\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Train model\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Evaluate model\n",
        "from torchmetrics import Accuracy, F1Score\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(101010)\n",
        "np.random.seed(101010)\n",
        "random.seed(101010)"
      ],
      "metadata": {
        "id": "ocQ45wDqcnRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Unzip the data folder\n",
        "if not os.path.exists('/content/data/chestxrays'):\n",
        "    with zipfile.ZipFile('/content/data/chestxrays.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/data')"
      ],
      "metadata": {
        "id": "v5zw49V1crJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations to apply to the images for use with ResNet-18\n",
        "transform_mean = [0.485, 0.456, 0.406]\n",
        "transform_std =[0.229, 0.224, 0.225]\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n",
        "\n",
        "# Apply the image transforms\n",
        "train_dataset = ImageFolder('/content/data/chestxrays/train', transform=transform)\n",
        "test_dataset = ImageFolder('/content/data/chestxrays/test', transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
      ],
      "metadata": {
        "id": "FQmTe8Q1cwv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------\n",
        "# Q2: Modify the model\n",
        "#--------------------------\n",
        "\n",
        "# Freeze the parameters of the model\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final layer for binary classification\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 1)\n",
        "\n",
        "#------------------------------\n",
        "# Q3a: Define the training loop\n",
        "#------------------------------\n",
        "\n",
        "# Model training/fine-tuning loop\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # Train the model for the specified number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Set the model to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize the running loss and accuracy\n",
        "        running_loss = 0.0\n",
        "        running_accuracy = 0\n",
        "\n",
        "        # Iterate over the batches of the train loader\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # Zero the optimizer gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Ensure labels have the same dimensions as outputs\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimizer step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the running loss and accuracy\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Calculate the train loss and accuracy for the current epoch\n",
        "        train_loss = running_loss / len(train_dataset)\n",
        "        train_acc = running_accuracy.double() / len(train_dataset)\n",
        "\n",
        "        # Print the epoch results\n",
        "        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n",
        "              .format(epoch+1, num_epochs, train_loss, train_acc))\n",
        "\n",
        "#-------------------------\n",
        "# Q3b: Fine-tune the model\n",
        "#-------------------------\n",
        "\n",
        "# Set the model to ResNet-18\n",
        "model = resnet18\n",
        "\n",
        "# Fine-tune the ResNet-18 model for 3 epochs using the train_loader\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "train(model, train_loader, criterion, optimizer, num_epochs=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "TNVHl0Yuea7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------\n",
        "# Evaluation code\n",
        "#-----------------------\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model = resnet18\n",
        "model.eval()\n",
        "\n",
        "# Initialize metrics for accuracy and F1 score\n",
        "accuracy_metric = Accuracy(task=\"binary\")\n",
        "f1_metric = F1Score(task=\"binary\")\n",
        "\n",
        "# Create lists store all predictions and labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "  for inputs, labels in test_loader:\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n",
        "\n",
        "    # Extend the lists with predictions and labels\n",
        "    all_preds.extend(preds.tolist())\n",
        "    all_labels.extend(labels.unsqueeze(1).tolist())\n",
        "\n",
        "    # Convert lists back to tensors\n",
        "    all_preds = torch.tensor(all_preds)\n",
        "    all_labels = torch.tensor(all_labels)\n",
        "\n",
        "    # Calculate accuracy and F1 score\n",
        "    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n",
        "    test_f1_score = f1_metric(all_preds, all_labels).item()\n",
        "\n",
        "print(f\"\\nTest accuracy: {test_accuracy:.3f}\\nTest F1-score: {test_f1_score:.3f}\")\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------------\n",
        "# Below is a sample code for the bonus task.\n",
        "# This code divides the training set into training and validation subsets.\n",
        "# You will have 150 examples per class for training and 50 for validation.\n",
        "# Don't forget to create new `val_dataset` and `val_loader` after running this code.\n",
        "#-----------------------------------------------------------------------------------\n",
        "'''\n",
        "import os, random, shutil\n",
        "\n",
        "# Function to move 50 random files from class folder in training to validation folder\n",
        "def move_files(src_class_dir, dest_class_dir, n=50):\n",
        "    if not os.path.exists(dest_class_dir):\n",
        "        os.makedirs(dest_class_dir)\n",
        "    files = os.listdir(src_class_dir)\n",
        "    random_files = random.sample(files, n)\n",
        "    for f in random_files:\n",
        "        shutil.move(os.path.join(src_class_dir, f), os.path.join(dest_class_dir, f))\n",
        "\n",
        "# Move 50 images from each class to validation folder\n",
        "move_files('data/chestxrays/train/NORMAL', 'data/chestxrays/val/NORMAL')\n",
        "move_files('data/chestxrays/train/PNEUMONIA', 'data/chestxrays/val/PNEUMONIA')"
      ],
      "metadata": {
        "id": "-yLDwXLXerIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}